{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from time import time\n",
    "test_features = pd.read_csv('X_test_df.csv')\n",
    "test_labels = pd.read_csv('y_test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for mdl in ['Logistic Regression', 'random_forest']:\n",
    "    models[mdl] = joblib.load('{}.pkl'.format(mdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Logistic Regression', GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 10, 100, 1000]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)), ('SVC', SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)), ('random_forest', RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=True, random_state=0, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
       "          param_distributions={'n_estimators': [700, 1000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [700, 1000, None], 'min_samples_split': [5, 10], 'min_samples_leaf': [4, 8], 'bootstrap': [True]},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic Regression': GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
      "          n_jobs=None, penalty='l2', random_state=0, solver='newton-cg',\n",
      "          tol=0.0001, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'C': [0.1, 10, 100, 1000]}, pre_dispatch='2*n_jobs',\n",
      "       refit=True, return_train_score='warn', scoring=None, verbose=0),\n",
      " 'SVC': SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      " 'random_forest': RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
      "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=True, random_state=0, verbose=0, warm_start=False),\n",
      "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
      "          param_distributions={'n_estimators': [700, 1000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [700, 1000, None], 'min_samples_split': [5, 10], 'min_samples_leaf': [4, 8], 'bootstrap': [True]},\n",
      "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred, average='micro'), 3)\n",
    "    recall = round(recall_score(labels, pred, average='micro'), 3)\n",
    "    \n",
    "    print('{} -- Accuracy: {} / Precision: {} / Recall: {} /'.format(name, accuracy,precision, recall))\n",
    "\n",
    "    \n",
    "    print()\n",
    "    print(\"Classification report for \", name)\n",
    "    print()\n",
    "    print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression -- Accuracy: 0.813 / Precision: 0.813 / Recall: 0.813 /\n",
      "\n",
      "Classification report for  Logistic Regression\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      2503\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.75      0.76      0.75      1444\n",
      "           3       0.00      0.00      0.00        81\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      4058\n",
      "   macro avg       0.40      0.41      0.40      4058\n",
      "weighted avg       0.79      0.81      0.80      4058\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC -- Accuracy: 0.817 / Precision: 0.817 / Recall: 0.817 /\n",
      "\n",
      "Classification report for  SVC\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      2503\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.76      0.75      0.76      1444\n",
      "           3       0.00      0.00      0.00        81\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      4058\n",
      "   macro avg       0.40      0.41      0.41      4058\n",
      "weighted avg       0.79      0.82      0.81      4058\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest -- Accuracy: 0.851 / Precision: 0.851 / Recall: 0.851 /\n",
      "\n",
      "Classification report for  random_forest\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      2503\n",
      "           1       1.00      0.07      0.12        30\n",
      "           2       0.81      0.79      0.80      1444\n",
      "           3       1.00      0.19      0.31        81\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      4058\n",
      "   macro avg       0.92      0.49      0.53      4058\n",
      "weighted avg       0.85      0.85      0.84      4058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
